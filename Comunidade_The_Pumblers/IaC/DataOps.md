# O que é DataOps?

DataOps é uma abordagem para a gestão de pipelones de dados, baseada em práticas DevOps, que se concentra na agilidade, qualidade e confiabilidade na entrega de dados.

É uma forma de otimizar os fluxos de trabalho dos pipelines de dados, do desenvolvimento à entrega, com objetivo de torná-los mais rápidos, confiáveis e escaláveis. Isso é alcançado através da automação de tarefas repetitivas, monitoramento contínuo e colaboração estreita entre equipes de desenvolvimento de software e dados.

## DataOps se concentra em três processos:

1. Redução de erros, o que melhora a confiança nos dados.
2. Ciclo de vida de um desenvolvimento, que envolve rapidez com que você pode obter novos modelos, novos conjuntos de dados e novas visualizações, da concepção do problema até a produção. Este aspecto envolve tanto velocidade quanto risco.
3. Aumento da produtividade da equipe, com redução do número de reuniões e aumento da colaboração.

Todos os processos definidos anteriormente são mensuráveis. Por exemplo, você deve analisar métricas que respondam às seguintes perguntas:
* Quanto trabalho sua equipe está fazendo?
* Com que frequência as coisas estão "quebrando"?
* Quão rápido você está colocando coisas novas em produção?

## Como Implementar DataOps?

### Definição de processos

Defina os processos de fluxo de trabalho para os pipelines de dados, incluindo a integração, validação, teste e implantação.

### Automatização:

Automatize tarefas repetitivas para melhorar a eficiência e a precisão. Isso inclui a automação de testes, implantações e atualizações.

### Colaboração

Crie uma equipe cross-funcional de desenvolvimento de software e de dados para trabalhar juntos na criação, manutenção e monitoramento dos pipelines de dados.

### Monitoramento

Monitore o desempenho de cada pipeline de dados para identificar problemas e oportunidades de melhoria.

### Feedback

Implemente um sistema de feedback para permitir que as equipes de desenvolvimento de software e de dados possam compartilhar informações e soluções em tempo real.

### Cultura

Fomente uma cultura de experimentação, inovação e melhoria contínua de experimentação, inovação e melhoria contínua para garantir que todos estejam sempre procurando formas de tornar cada pipeline de dados mais eficiente e eficaz.

## Ferramentas de DataOps

* Apache Airflow: um sistema de orquestração de pipeline de dados baseado em tarefas.
* AWS Glue: um serviço de ETL da Amazon que permite a criação, execução e gerenciamento de pipelines de dados.
* Talend: uma plataforma de integração de dados oferece ferramentas para coletar, integrar e distribuir dados.
* Apache Nifi: um sistema de fluxo de dados de código aberto para automatizar a movimentação e o tratamento de dados.
* StreamSets: uma plataforma de gerenciamento de dados que permite a cração, execução e monitoramento de pipelines de dados.
* DataKitchen: uma plataforma de automação em DataOps